{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/missriri/IS-II/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tPJ9LWmwip68"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import SGD, Adam\n",
        "#from keras import np_utils\n",
        "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
        "from sklearn import metrics\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "tf.config.run_functions_eagerly(True)\n",
        "tf.data.experimental.enable_debug_mode()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"QvDpQHBoHShaC0LOwPbc\")\n",
        "project = rf.workspace(\"nir\").project(\"recycling-codes-detection-v2\")\n",
        "dataset = project.version(2).download(\"tfrecord\")\n"
      ],
      "metadata": {
        "id": "TtcqLjGp5Mhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a parsing function to extract data from the TFRecords\n",
        "@tf.function\n",
        "def parse_tfrecord_fn(example):\n",
        "    feature_description = {\n",
        "        'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
        "        'image/format': tf.io.FixedLenFeature([], tf.string),\n",
        "        'image/object/class/label': tf.io.VarLenFeature(tf.int64),\n",
        "        # Add more feature descriptions as needed\n",
        "    }\n",
        "\n",
        "    example = tf.io.parse_single_example(example, feature_description)\n",
        "\n",
        "    # Decode and preprocess the image\n",
        "    image = tf.image.decode_jpeg(example['image/encoded'], channels=3)\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "\n",
        "    # Extract the label IDs\n",
        "    label_ids = example['image/object/class/label']\n",
        "\n",
        "    # Define your label map based on the class names and IDs\n",
        "    label_map = {\n",
        "        1: \"1_PET\",\n",
        "        2: \"2_PEHD\",\n",
        "        3: \"3_PVC\",\n",
        "        4: \"4_PELD\",\n",
        "        5: \"5_PP\",\n",
        "        6: \"6_PS\",\n",
        "        7: \"7_Other\"\n",
        "    }\n",
        "\n",
        "    # Create a StaticHashTable for label conversion\n",
        "    label_table = tf.lookup.StaticHashTable(\n",
        "        tf.lookup.KeyValueTensorInitializer(\n",
        "            list(label_map.keys()), list(label_map.values()),\n",
        "            key_dtype=tf.int64, value_dtype=tf.string),\n",
        "        default_value=\"Unknown\"\n",
        "    )\n",
        "\n",
        "    # Convert label IDs to class names using the label map\n",
        "    class_names = label_table.lookup(label_ids.values)\n",
        "\n",
        "    # Print the class names to verify the conversion\n",
        "    print(\"Class Names:\", class_names)\n",
        "\n",
        "    return image, class_names\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "X0jENa-qDVKB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfrecord_files = 'recycling-codes-detection-v2-2/train/*.tfrecord'\n",
        "\n",
        "# Create a TFRecord dataset\n",
        "dataset = tf.data.TFRecordDataset(tf.data.Dataset.list_files(tfrecord_files))\n",
        "\n",
        "# Apply the parsing function to the dataset\n",
        "parsed_dataset = dataset.map(parse_tfrecord_fn)\n",
        "\n",
        "# You can now iterate through the dataset and access the parsed data\n",
        "for image, class_names in parsed_dataset:\n",
        "    # Access the image and class names for each example\n",
        "    print(\"Image Shape:\", image.shape)\n",
        "    print(\"Class Names:\", class_names)"
      ],
      "metadata": {
        "id": "vCZMM5TaECkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through the dataset and display the first image\n",
        "for image, class_names in parsed_dataset:\n",
        "    # Display the first image\n",
        "    plt.imshow(image.numpy())  # Convert the TensorFlow tensor to a NumPy array\n",
        "\n",
        "    # Convert byte strings to regular strings and join them\n",
        "    class_names_str = ', '.join([name.decode() for name in class_names.numpy()])\n",
        "\n",
        "    plt.title(\"Class Names: \" + class_names_str)  # Use the decoded class names\n",
        "    plt.show()\n",
        "    break  # Display only the first image"
      ],
      "metadata": {
        "id": "HtRjK24YGa-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset 2\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"QvDpQHBoHShaC0LOwPbc\")\n",
        "project = rf.workspace(\"thesis-dataset-5dsvz\").project(\"ric\")\n",
        "dataset2 = project.version(1).download(\"tfrecord\")\n",
        "\n"
      ],
      "metadata": {
        "id": "xiiKTdCxmFs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (dataset2)\n",
        "print (dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8Z4rzGyMJW-",
        "outputId": "5fbc6c81-7361-4ccc-ce60-de4b9e410234"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<roboflow.core.dataset.Dataset object at 0x7fa3d54efbe0>\n",
            "<TFRecordDatasetV2 element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "import re\n",
        "import uuid\n",
        "\n",
        "\n",
        "def convert_label_ids(label_ids):\n",
        "    def convert(label_id):\n",
        "        if not label_id.indices.shape[0] == 0:\n",
        "            class_id = label_id.values[0].numpy()\n",
        "            class_name = label_map1[class_id]\n",
        "        else:\n",
        "            class_name = \"\"  # Handle empty label_id\n",
        "        if class_name in class_mapping:\n",
        "            class_name = class_mapping[class_name]\n",
        "        return class_name\n",
        "\n",
        "    label_names = tf.py_function(convert, inp=[label_ids], Tout=tf.string, name=\"convert_label_ids\")\n",
        "    return label_names\n",
        "\n",
        "def strip_class_name(class_name):\n",
        "  class_name_as_string = tf.strings.as_string(class_name)\n",
        "  class_name_string = tf.strings.regex_replace(class_name_as_string, r\"[^\\d-]\", \"\")  # Apply regex substitution\n",
        "  return  class_name_string\n",
        "\n",
        "\n",
        "def parse_tfrecord_fn(example, label_map):\n",
        "    feature_description = {\n",
        "        'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
        "        'image/format': tf.io.FixedLenFeature([], tf.string),\n",
        "        'image/object/class/label': tf.io.VarLenFeature(tf.int64),\n",
        "        # Add more feature descriptions as needed\n",
        "    }\n",
        "\n",
        "    example = tf.io.parse_single_example(example, feature_description)\n",
        "\n",
        "    # Decode and preprocess the image\n",
        "    image = tf.image.decode_jpeg(example['image/encoded'], channels=3)\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "\n",
        "    # Extract the label IDs\n",
        "    label_ids = example['image/object/class/label']\n",
        "    print(label_ids)\n",
        "\n",
        "    # Use tf.py_function to convert label IDs to class names\n",
        "    class_names = tf.py_function(convert_label_ids, inp=[label_ids], Tout=tf.string, name=\"convert_label_ids\")\n",
        "    print(\"----class name----\\n\",class_names)\n",
        "\n",
        "    return image, class_names\n",
        "\n",
        "# Define the paths to the TFRecord files for dataset 1 and dataset 2\n",
        "tfrecord_files1 = 'recycling-codes-detection-v2-2/train/*.tfrecord'\n",
        "tfrecord_files2 = 'RIC-1/train/*.tfrecord'\n",
        "\n",
        "# Create a TFRecord dataset for dataset 1\n",
        "dataset1 = tf.data.TFRecordDataset(tf.data.Dataset.list_files(tfrecord_files1))\n",
        "\n",
        "# Create a TFRecord dataset for dataset 2\n",
        "dataset2 = tf.data.TFRecordDataset(tf.data.Dataset.list_files(tfrecord_files2))\n",
        "\n",
        "# Define a mapping between class labels in dataset 1 and dataset 2\n",
        "class_mapping = {\n",
        "    \"2_PEHD\": \"2_PEHD\",  # No change for dataset 1 labels\n",
        "    \"4_PELD\": \"4_PELD\",  # No change for dataset 1 labels\n",
        "    \"2_HDPE\": \"2_PEHD\",  # Merge dataset 2 \"2_HDPE\" into dataset 1 \"2_PEHD\"\n",
        "    \"4_LDPE\": \"4_PELD\",  # Merge dataset 2 \"4_LDPE\" into dataset 1 \"4_PELD\"\n",
        "}\n",
        "\n",
        "# Define the label maps for both datasets\n",
        "label_map1 = {\n",
        "    1: \"1_PET\",\n",
        "    2: \"2_PEHD\",\n",
        "    3: \"3_PVC\",\n",
        "    4: \"4_PELD\",\n",
        "    5: \"5_PP\",\n",
        "    6: \"6_PS\",\n",
        "    7: \"7_Other\"\n",
        "}\n",
        "\n",
        "label_map2 = {\n",
        "    1: \"1_PET\",\n",
        "    2: \"2_HDPE\",\n",
        "    3: \"4_LDPE\",\n",
        "    4: \"5_PP\",\n",
        "}\n",
        "\n",
        "# Parse the datasets using the parse_tfrecord_fn and label maps\n",
        "parsed_dataset1 = dataset1.map(lambda example: parse_tfrecord_fn(example, label_map1))\n",
        "parsed_dataset2 = dataset2.map(lambda example: parse_tfrecord_fn(example, label_map2))\n",
        "\n",
        "# Define the directory where the combined dataset will be saved\n",
        "combined_dataset_dir = \"combined-dataset\"\n",
        "\n",
        "# Create subfolders for each unique class label (taking into account class mapping)\n",
        "unique_labels = set()\n",
        "\n",
        "# Parse dataset1 and add unique labels to the set\n",
        "for example in dataset1:\n",
        "    image, class_names = parse_tfrecord_fn(example, label_map1)\n",
        "    if isinstance(class_names, int):\n",
        "        class_name = str(class_names)\n",
        "    elif isinstance(class_names, bytes):\n",
        "        class_name = class_names.decode()\n",
        "    elif isinstance(class_names, str):\n",
        "        class_name = class_names\n",
        "    else:\n",
        "        class_name = ''\n",
        "\n",
        "    if class_name in class_mapping:\n",
        "        class_name = class_mapping[class_name]\n",
        "    if class_name:\n",
        "        unique_labels.add(class_name)\n",
        "\n",
        "# Parse dataset2 and add unique labels to the set\n",
        "for example in dataset2:\n",
        "    image, class_names = parse_tfrecord_fn(example, label_map2)\n",
        "    if isinstance(class_names, int):\n",
        "        class_name = str(class_names)\n",
        "    elif isinstance(class_names, bytes):\n",
        "        class_name = class_names.decode()\n",
        "    elif isinstance(class_names, str):\n",
        "        class_name = class_names\n",
        "    else:\n",
        "        class_name = ''\n",
        "\n",
        "    if class_name:\n",
        "        unique_labels.add(class_name)\n",
        "\n",
        "# Create subfolders for each unique class label\n",
        "for label in unique_labels:\n",
        "    label_dir = os.path.join(combined_dataset_dir, label)\n",
        "    os.makedirs(label_dir, exist_ok=True)\n",
        "\n",
        "# Create a function to extract the class name from a label\n",
        "def extract_class_name(label):\n",
        "    print('unsplit class name is',label.numpy().decode())\n",
        "    class_name = label.numpy().decode().split('_')[-1]\n",
        "    print('class name is:',class_name)\n",
        "    return class_name\n",
        "\n",
        "# Parse and copy images to their respective class label subfolders\n",
        "for example in dataset1:\n",
        "    image, label = parse_tfrecord_fn(example, label_map1)\n",
        "    class_name = extract_class_name(label)\n",
        "\n",
        "    unique_labels.add(class_name)\n",
        "\n",
        "    # Debugging information\n",
        "    print('---dataset 1---')\n",
        "    print(f\"Image class: {class_name}\")\n",
        "    print(f\"Image shape: {image.shape}\")\n",
        "    print(f\"Label: {label.numpy().decode()}\")\n",
        "\n",
        "\n",
        "    if class_name in class_mapping:\n",
        "        class_name = class_mapping[class_name]\n",
        "\n",
        "    # save the image to the corresponding subfolder\n",
        "    image_bytes = image.numpy().tobytes()\n",
        "    image_hash = hash(image_bytes)\n",
        "    image_filename = f\"{class_name}_{image_hash}.jpg\"\n",
        "\n",
        "    class_dir = os.path.join(combined_dataset_dir, class_name)\n",
        "    os.makedirs(class_dir, exist_ok=True) # Create the directory if it doesn't exist\n",
        "    output_path = os.path.join(class_dir, image_filename)\n",
        "\n",
        "    # Convert the image data type to uint8\n",
        "    image = tf.image.convert_image_dtype(image, tf.uint8)\n",
        "    # Encode the image as JPEG\n",
        "    image_data = tf.image.encode_jpeg(image)\n",
        "\n",
        "    with open(output_path, \"wb\") as img_file:\n",
        "        img_file.write(image_data.numpy())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for example in dataset2:\n",
        "    image, class_names = parse_tfrecord_fn(example, label_map2)\n",
        "    class_name = extract_class_name(label)\n",
        "\n",
        "    if class_name in class_mapping:\n",
        "        class_name = class_mapping[class_name]\n",
        "\n",
        "     # Debugging information\n",
        "    print('---dataset 1---')\n",
        "    print(f\"Image class: {class_name}\")\n",
        "    print(f\"Image shape: {image.shape}\")\n",
        "    print(f\"Label: {label.numpy().decode()}\")\n",
        "\n",
        "    image_bytes = image.numpy().tobytes()\n",
        "    image_hash = hash(image_bytes)\n",
        "    image_filename = f\"{class_name}_{image_hash}.jpg\"\n",
        "\n",
        "    class_dir = os.path.join(combined_dataset_dir, class_name)\n",
        "    os.makedirs(class_dir, exist_ok=True)\n",
        "    output_path = os.path.join(class_dir, image_filename)\n",
        "\n",
        "    # Convert the image data type to uint8\n",
        "    image = tf.image.convert_image_dtype(image, tf.uint8)\n",
        "    # Encode the image as JPEG\n",
        "    image_data = tf.image.encode_jpeg(image)\n",
        "\n",
        "    with open(output_path, \"wb\") as img_file:\n",
        "        img_file.write(image_data.numpy())\n",
        "\n"
      ],
      "metadata": {
        "id": "wnVN_pR9FvWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Raw images dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Change directory to where images are stored in  Google Drive\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/plastics')\n",
        "\n",
        "!ls\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMIioVELY2kL",
        "outputId": "f0d64dcb-85f6-40e4-d1d1-5f8a72620595"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "HDPEM  PET\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import glob\n",
        "# combine all datasets together then split them into training, testing and validation\n",
        "# datasets\n",
        "\n",
        "combined_dataset_dir = \"combined-dataset\"\n",
        "\n",
        "#get a list of image files\n",
        "image_files = glob.glob(os.path.join(combined_dataset_dir, \"*\", \"*.jpg\"))\n",
        "#extract labels\n",
        "labels = [os.path.basename(os.path.dirname(file_path)) for file_path in image_files]\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2QaBqbmifkLX"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "#initialize IDG for augmentation and preprocessing\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255.0,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")"
      ],
      "metadata": {
        "id": "bVec245ThDhZ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create generators for loading images from directories and performing data augmentation\n",
        "train_dir = os.path.join(combined_dataset_dir, \"train\")\n",
        "test_dir = os.path.join(combined_dataset_dir, \"test\")\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dK1GYQGrUz52"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define batch size and image size\n",
        "batch_size = 32\n",
        "image_size = (150, 150)\n",
        "\n",
        "# Flow training images in batches using train_datagen\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(640, 640),  # Update the target size\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Flow validation images in batches using validation_datagen\n",
        "test_generator = datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(640, 640),  # Update the target size\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dE8cKzQwjLdx",
        "outputId": "8c345384-1dd3-4ebd-82d5-c5036e9d8167"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 images belonging to 0 classes.\n",
            "Found 0 images belonging to 0 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir, test_dir = tf.keras.utils.image_dataset_from_directory(\n",
        "    combined_dataset_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"both\",\n",
        "    seed=1337,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "EUAVDMjUkq7L",
        "outputId": "43d1971b-1769-4e6b-f8f9-aac170a75b29"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 files belonging to 2 classes.\n",
            "Using 0 files for training.\n",
            "Using 0 files for validation.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-0ca6b0b1adcb>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_dir, test_dir = tf.keras.utils.image_dataset_from_directory(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mcombined_dataset_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"both\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1337\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/image_dataset.py\u001b[0m in \u001b[0;36mimage_dataset_from_directory\u001b[0;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, **kwargs)\u001b[0m\n\u001b[1;32m    241\u001b[0m         )\n\u001b[1;32m    242\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mimage_paths_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    244\u001b[0m                 \u001b[0;34mf\"No training images found in directory {directory}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m                 \u001b[0;34mf\"Allowed formats: {ALLOWLIST_FORMATS}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No training images found in directory combined-dataset. Allowed formats: ('.bmp', '.gif', '.jpeg', '.jpg', '.png')"
          ]
        }
      ]
    }
  ]
}